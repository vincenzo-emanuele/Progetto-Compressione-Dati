\phantomsection
%\addcontentsline{toc}{chapter}{Introduzione}
\chapter{Introduzione}
\markboth{Introduzione}{}
% [titolo ridotto se non ci dovesse stare] {titolo completo}

\begin{citazione}
Nell'ambito del presente capitolo verrà effettuata una panoramica generale sulle problematiche trattate dal lavoro svolto, motivando la necessità della costruzione di un algoritmo di compressione sicura di testo. Verrà, successivamente, presentata un'idea ad alto livello della soluzione proposta, evidenziando le modalità mediante le quali questa vada a risolvere le problematiche descritte. Infine, verrà descritta la struttura del lavoro presentato in termini di suddivisione in capitoli. 
\end{citazione}
\newpage

\section{Problematiche trattate} { \setstretch{1.3}
Una delle operazioni fondamentali nell'ambito del \emph{processing} delle stringhe è il \textbf{pattern matching}: tale operazione consiste nell'individuazione di tutte le occorrenze di un determinato \emph{pattern} in una data stringa input. È possibile effettuare tale tipo di operazione su dati compressi seguendo diverse strategie, la più semplice delle quali consiste nel decomprimere, in primo luogo, il file per poi successivamente effettuare le operazioni di \emph{pattern matching} sul file decompresso. Per questioni legate alle prestazioni e all'utilizzo della memoria, vengono generalmente preferite strategie che non richiedano una decompressione dei file e che riescano a lavorare sui file compressi. Al fine di raggiungere tale obiettivo è necessario utilizzare indici di dati compressi che, se dovessero essere conservati su server di terze parti, porterebbero a gravi problematiche di privacy e confidenzialità. La soluzione concettualmente più semplice consiste nel cifrare i dati dopo che questi sono stati compressi, seguendo, in questo modo, il paradigma \emph{encryption-after-compression}. Ulteriori approcci studiati in letteratura consistono nell'integrazione di compressione e cifratura in un unico passaggio sfruttando strutture di dati compressi utilizzate nei classici algoritmi di compressione. Diverse ricerche hanno, tuttavia, mostrato che tali approcci presentano diverse problematiche di sicurezza. In particolare il paradigma \emph{encryption-after-compression} risulta essere insicuro anche nell'ambito di noti compressori come \emph{WinZip 9.0} \cite{kohno2004attacking} \cite{phong2010password}, \emph{WinRAR 3.42} \cite{yeo2006security} e \emph{PKZIP 1.10 e 2.04g} \cite{stay2001zip} \cite{biham1994known}. Infine risulta opportuno sottolineare che nessuno degli approcci discussi fino a questo momento risulta essere in grado di conservare le strutture necessarie al pattern matching.
\section{Soluzione proposta} %descrizione della soluzione all'encryption after compression
Le problematiche che sorgono dalla ricerca di una strategia volta alla costruzione di un algoritmo in grado di svolgere le operazioni di \emph{pattern matching} su dati compressi, portano alla necessità di progettare un approccio \emph{ad-hoc} per risolvere i problemi di sicurezza presenti nelle diverse soluzioni discusse. Gli autori del paper \emph{Secure Compression and Pattern Matching Based on Burrows-Wheeler Transform} \cite{zeng2018secure} hanno proposto una soluzione basata su alcuni algoritmi (ben noti in letteratura) revisionati al fine di garantire le proprietà di sicurezza che li rendano adatti ad un utilizzo reale. La \emph{pipeline} proposta dagli autori del paper \cite{zeng2018secure} è costruita come segue:
\begin{itemize}
    \item La stringa input viene data all'algoritmo \textbf{sBWT (scrambled Burrows-Wheeler Transform)}. L'output dell'algoritmo sarà una permutazione della stringa input avente lunghe sequenze di caratteri ripetuti vicini tra loro;
    \item L'output della \emph{sBWT} viene dato in input alla \textbf{bMTF (blocky Move-To-Front}). Sfruttando il fatto che la \emph{sBWT} restituisca lunghe sequenze di caratteri ripetuti vicini tra loro, tale algoritmo costruisce un output contenente lunghe sequenza di \emph{0}; 
    \item L'output della \emph{bMTF} viene dato in input alla \textbf{RLE (Run-Length Encoding)}. Tale algoritmo fornisce una codifica compatta dell'input facendo uso di un contatore per esprimere in maniera concisa le sequenze di \emph{0} ripetuti;
    \item L'ultimo passo della \emph{pipeline} consiste nell'applicazione di un algoritmo di \textbf{Prefix Code} sull'output della \emph{RLE}. La scelta dell'algoritmo di \emph{Prefix Code} influisce sul rapporto di compressione dell'algoritmo complessivo;
\end{itemize}
La pipeline descritta fa uso di un layer di sicurezza implementato dagli algoritmi \emph{sBWT} e \emph{bMTF} che risultano essere, rispettivamente, la revisione degli algoritmi noti in letteratura come \emph{Burrows-Wheeler Transform (BWT)} e \emph{Move-To-Front (MTF)}. L'algoritmo proposto, inoltre, costruisce due strutture dati ausiliarie che vengono sfruttate per il \emph{pattern matching}. Tali strutture vengono opportunamente manipolate al fine di evitare l'introduzione di vulnerabilità che vanno ad intaccare il layer di sicurezza implementato. La costruzione di tali strutture ed il protocollo utilizzato per l'implementazione del pattern matching sono ampiamente trattati in \cite{zeng2018secure}. Il presente lavoro si pone l'obiettivo di effettuare una panoramica dettagliata della pipeline proposta dagli autori del paper \cite{zeng2018secure} e di proporre un'implementazione in \emph{Python} di un algoritmo di compressione \textbf{lossless} sicura di testo che sfrutti tale \emph{pipeline} e che risulti essere quanto più efficiente possibile puntando a massimizzare il fattore di compressione. Risulta, infine, doveroso sottolineare che l'algoritmo proposto risulta essere sicuro secondo la definizione di sicurezza denominata \textbf{IND-CPA sicurezza} opportunamente definita dagli autori del paper \cite{zeng2018secure} stesso, dal quale è possibile reperire ulteriori dettagli sull'algoritmo di \emph{pattern matching} e sulle garanzie di sicurezza in termini matematici e formali.
\section{Struttura della tesina} 
La trattazione del presente lavoro viene suddivisa in cinque capitoli di cui viene fornita, di seguito, una breve descrizione:
\begin{itemize}
    \item Il capitolo 1 introduce le problematiche trattate e la soluzione proposta;
    \item Il capitolo 2 effettua una trattazione degli algoritmi utilizzati dalla \emph{pipeline} proposta analizzando le motivazioni che hanno portato alla scelta di tali algoritmi;
    \item Il capitolo 3 analizza gli algoritmi trattati nel precedente capitolo ponendo particolare enfasi sulle scelte implementative che hanno portato all'ottenimento di determinati risultati in termini prestazionali e di fattore di compressione;
    \item Il capitolo 4 descrive l'attività di testing svolta nell'ambito dell'implementazione proposta, presentando i risultati ottenuti utilizzando il \emph{Dataset} considerato;
    \item Il capitolo 5 conclude la trattazione con diverse considerazioni finali sul lavoro svolto e sugli eventuali sviluppi futuri;
\end{itemize}
}